{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Analytics and Visualization\n",
    "\n",
    "## Notebook 1: Loading data from the internet and saving it to your computer\n",
    "\n",
    "v1.0, December 21, 2020, Copyright &copy; Ken Urquhart\n",
    "\n",
    "The latest version of this notebook can be found at:\n",
    "\n",
    "* https://github.com/KenU798/Analytics-and-Data-Visualization-for-COVID-19\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "* [0. Loading libraries and setting options](#s0)\n",
    "* [1. COVID Tracking Project data for the USA (by County) in CSV format](#s1)\n",
    "* [2. COVID Act Now time series data for the USA (by County) in CSV format ](#s2)\n",
    "* [3. John's Hopkins time series data for the USA (by County) in CSV format](#s3)\n",
    "* [4. John's Hopkins global time series data in CSV format](#s4)\n",
    "* [5. Mapping and Location Data](#s5)\n",
    "* [6. Countries of the world boundaries](#s6)\n",
    "* [7. U.S. State and County geographic boundaries](#s7)\n",
    "* [8. The data is downloaded and ready for use](#s8)\n",
    "\n",
    "\n",
    "# COVID-19 in December 2020\n",
    "\n",
    "* Over 15 million Americans have contracted COVID-19 and more than 300,000 have died.\n",
    "* Globally there have been more than 76.9 million cases and 1.7 million deaths.\n",
    "\n",
    "COVID-19 appears to be 5x more deadly than the worst flu season we went through in the last 10 years.\n",
    "\n",
    "While vaccines are being approved for use, it will be at least 2 months before those who receive initial vaccinations might be immunue...and even longer before most of us will have access to a vaccine.\n",
    "\n",
    "And we are now facing a strong resurgence of COVID-19 as we go into winter.\n",
    "\n",
    "Everywhere you look in the news, you see COVID-19 stories with:\n",
    "\n",
    "* Graphs and tables showing infection growth, current hospitalizations, ICU beds in use, etc.\n",
    "* Interactive graphs with pop-ups show even more information when you hover over lines or points\n",
    "* Graphs that overlay data and maps of U.S. states and counties\n",
    "* Maps with time-based sliders that show the progression of cases and deaths\n",
    "\n",
    "And you can create any and all of these visualizations using published COVID-19 data and free data science tools.\n",
    "\n",
    "## Learning data science by studying COVID-19 public data\n",
    "\n",
    "Learning how to do these for COVID-19 data offers you a great opportunity to learn how to turn raw data into high-impact analyses and visualizations...and along the way you will learn a lot about using Python, platform independent data preparation, and interactive presentation tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Loading libraries and setting options <a class=\"anchor\" id=\"s1\"></a>\n",
    "\n",
    "Let's get started by importing the Python `libraries` we will need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with data and doing analytics\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# for working with zip files\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen, urlcleanup\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# for working with directories and files\n",
    "import shutil\n",
    "from pathlib import Path # OS independent way of dealing with files and paths\n",
    "\n",
    "# for working with dates and timestamped data\n",
    "from datetime import datetime\n",
    "\n",
    "# for visualization and interactive plots and maps\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import plotly as px\n",
    "import folium\n",
    "from folium import plugins\n",
    "import branca.colormap as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I'm exploring a new datasets, I like to see all the columns displayed.\n",
    "\n",
    "Here is a code block that turns on and off display switches for `DataFrames`.\n",
    "\n",
    "You can read more here: https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see all pandas options\n",
    "#pd.describe_option()\n",
    "\n",
    "# Display all columns (with restore default truncation commented out)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.reset_option('display.max_columns')\n",
    "\n",
    "# Display all rows (with restore default truncation)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.reset_option('display.max_rows')\n",
    "\n",
    "# Set maximum column widths when displaying (with reset)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#pd.reset_option('display.max_colwidth')\n",
    "\n",
    "# When you don't want to change default options,\n",
    "# this function displays the passed-in dataframe in full.\n",
    "def pd_show_full(df):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', None):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder in this notebook's working directory to store all the data files I download.\n",
    "\n",
    "Name the folder with today's date, delete the directory and its contents if it already exists, delete the file if it has the same name as the directory, and then create an empty folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = Path(datetime.today().strftime('%Y-%m-%d') + '-COVID-19-Data')\n",
    "display(download_folder)\n",
    "\n",
    "if download_folder.is_dir():\n",
    "    shutil.rmtree(download_folder)\n",
    "elif download_folder.is_file():\n",
    "    download_folder.unlink()\n",
    "\n",
    "download_folder.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 data sources and how to download them\n",
    "\n",
    "I will use 3 sources of COVID-19 information. Each one provides different levels of detail on the data.\n",
    "\n",
    "Depending on your Internet connection, it may take a long time to download each dataset.\n",
    "\n",
    "I save each file into the directory you are running this notebook in using the `pickle` format.\n",
    "\n",
    "Read more there: https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "`Pickle` compresses the data in a format that is read quickly into `DataFrames`.\n",
    "\n",
    "## WARNING: the pickle module is not secure\n",
    "\n",
    "Malicious pickle data files can be created that execute arbitrary code during unpickling. Never unpickle data from untrusted sources.\n",
    "\n",
    "This notebook writes and reads its own `pickle` files locally. No pickle files are read from the Interent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. COVID Tracking Project data for the USA (by County) in CSV format <a class=\"anchor\" id=\"s1\"></a>\n",
    "\n",
    "Detailed COVID-19 data for the United States in one `.csv` file.\n",
    "\n",
    "See their dashboard at: https://covidtracking.com/data\n",
    "\n",
    "From their website:\n",
    "\n",
    ">Every day, our volunteers compile the latest numbers on tests, cases, hospitalizations, and patient outcomes from every US state and territory.\n",
    "\n",
    "The data can be downloaded directly into a `DataFrame` and saved locally in a `pickle` file for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTP_all_states = 'https://api.covidtracking.com/v1/states/daily.csv'\n",
    "\n",
    "df_CTP = pd.read_csv(CTP_all_states)\n",
    "\n",
    "df_CTP.to_pickle(download_folder / 'covid_tracking_project.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did you get a warning message when you ran the cell?**\n",
    "\n",
    "If you did, you are being warned that some of the non-numeric columns in the `DataFrame` contain missing data. Missing data cells are filled with `NaN`s by default. When that happens in columns of strings and dates (non-numeric data) you get the warning.\n",
    "\n",
    "Ignore that for now. I'll deal with it later during analysis.\n",
    "\n",
    "Here's the `DataFrame` with all columns displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID Tracking Project data dictionary\n",
    "\n",
    "The data dictionary explaining what each column contains is located in the \"Historic values for all states\" section of their web page: https://covidtracking.com/data/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. COVID Act Now time series data for the USA (by County) in CSV format <a class=\"anchor\" id=\"s2\"></a>\n",
    "\n",
    "Detailed data for all United States in one `.csv` file. See their dashboard at:\n",
    "\n",
    "https://covidtracking.com/data\n",
    "\n",
    "From their website:\n",
    "\n",
    ">Covid Act Now is a 501(c)(3) nonprofit founded in March 2020. We strive to provide the most timely and accurate local COVID data so that every American can make informed decisions during the pandemic. We are committed to:\n",
    ">\n",
    "> **Data**: We support data- and science-backed policies and decision-making\n",
    ">\n",
    "> **Transparency**: Our data and methodologies are fully open-source so that the public can vet, freely use, and build upon our work\n",
    ">\n",
    "> **Accessibility**: We make data universally accessible so that anyone can easily understand and use it, regardless of ability or prior knowledge\n",
    "\n",
    "They have a website API that needs a free access code you can get by registering here (you need to supply an e-mail address and a little information on what you will use the data for):\n",
    "\n",
    "https://apidocs.covidactnow.org/access\n",
    "\n",
    "Once you have your API key, the data can be downloaded using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CAN_Key = '<your key here>' # replace with your API key\n",
    "CAN_File = 'states.timeseries.csv'\n",
    "\n",
    "df_CAN = pd.read_csv(f'https://api.covidactnow.org/v2/{CAN_File}?apiKey={CAN_Key}')\n",
    "df_CAN.to_pickle(download_folder / 'covid_act_now.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_CAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. John's Hopkins time series data for the USA (by County) in CSV format <a class=\"anchor\" id=\"s3\"></a>\n",
    "\n",
    "Home page at John's Hopkins University: https://coronavirus.jhu.edu\n",
    "\n",
    "Raw data home page on Github: https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "From their website:\n",
    "\n",
    "> The Johns Hopkins Coronavirus Resource Center (CRC) is a continuously updated source of COVID-19 data and expert guidance. We aggregate and analyze the best data available on COVID-19—including cases, as well as testing, contact tracing and vaccine efforts—to help the public, policymakers and healthcare professionals worldwide respond to the pandemic.\n",
    "\n",
    "## Loading JHU COVID-19 Data into a DataFrame\n",
    "\n",
    "JHU stores their data in `.csv` files and can be downloaded directly or read directly via URL from `Github`.\n",
    "\n",
    "You have to watch out for John's Hopkins updating their data access URLs from time to time when they re-organize their Github repository.\n",
    "\n",
    "Download confirmed U.S. cases by county, state, and date (international data by country is also available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JHU_Github_URL = 'https://raw.githubusercontent.com/CSSEGISandData/'\n",
    "JHU_Github_Path = 'COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "\n",
    "JHU_File_US_confirmed = 'time_series_covid19_confirmed_US.csv'\n",
    "JHU_File_US_deaths = 'time_series_covid19_deaths_US.csv'\n",
    "\n",
    "df_JHU_US_confirmed = pd.read_csv(JHU_Github_URL + JHU_Github_Path + JHU_File_US_confirmed)\n",
    "df_JHU_US_confirmed.to_pickle(download_folder / 'jhu_confirmed_us.pkl')\n",
    "\n",
    "df_JHU_US_deaths = pd.read_csv(JHU_Github_URL + JHU_Github_Path + JHU_File_US_deaths)\n",
    "df_JHU_US_deaths.to_pickle(download_folder / 'jhu_deaths_us.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JHU_US_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JHU_US_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. John's Hopkins global time series data in CSV format <a class=\"anchor\" id=\"s4\"></a>\n",
    "\n",
    "JHU also provides time series data for most countries of the world in a separate `.csv` file.\n",
    "\n",
    "Download and save international data by country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JHU_File_Global_confirmed = 'time_series_covid19_confirmed_global.csv'\n",
    "JHU_File_Global_deaths = 'time_series_covid19_deaths_global.csv'\n",
    "\n",
    "df_JHU_Global_confirmed = pd.read_csv(JHU_Github_URL + JHU_Github_Path + JHU_File_Global_confirmed)\n",
    "df_JHU_Global_confirmed.to_pickle(download_folder / 'jhu_confirmed_global.pkl')\n",
    "\n",
    "df_JHU_Global_deaths = pd.read_csv(JHU_Github_URL + JHU_Github_Path + JHU_File_Global_deaths)\n",
    "df_JHU_Global_deaths.to_pickle(download_folder / 'jhu_deaths_global.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JHU_Global_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_JHU_Global_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Mapping and Location Data <a class=\"anchor\" id=\"s5\"></a>\n",
    "\n",
    "## Load and save the JHU Map Dataset\n",
    "\n",
    "JHU also provides detailed data on populations and County/State/Province/Municipality/etc. description codes and location data.\n",
    "\n",
    "This data is used to create interactive maps and normalizing case numbers per 100,000 people so you can compare numbers from different locations.\n",
    "\n",
    "The detailed explanation of the file contents is at: https://github.com/CSSEGISandData/COVID-19_Unified-Dataset\n",
    "\n",
    "Don't worry right now if a lot of this table does not make sense. I'll be using it regularly during analysis and visualization - when you will see what each column can be used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JHU_Github_Path2 = 'COVID-19_Unified-Dataset/master/'\n",
    "JHU_geo_data = 'COVID-19_LUT.csv'\n",
    "\n",
    "df_JHU_geo_data = pd.read_csv(JHU_Github_URL + JHU_Github_Path2 + JHU_geo_data)\n",
    "df_JHU_geo_data.to_pickle(download_folder / 'jhu_geo_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JHU_geo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Countries of the world boundaries <a class=\"anchor\" id=\"s6\"></a>\n",
    "\n",
    "When making maps, you need the geographic boundaries of all the countries of the world. Fortunately this data is publicly (and freely) available for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_url = 'https://www.naturalearthdata.com/http//www.naturalearthdata.com/'\n",
    "zip_file_path = 'download/10m/cultural/ne_10m_admin_0_countries.zip'\n",
    "\n",
    "sub_folder = download_folder / 'shapes_global'\n",
    "\n",
    "urlcleanup()\n",
    "with urlopen(geodata_url + zip_file_path) as zip_response:\n",
    "    with ZipFile(BytesIO(zip_response.read())) as zip_file:\n",
    "        zip_file.extractall(sub_folder)\n",
    "        \n",
    "gdf_Global = gpd.read_file(sub_folder / 'ne_10m_admin_0_countries.shp')\n",
    "gdf_Global.to_pickle(download_folder / 'ne_10m_admin_0_countries.pkl')\n",
    "\n",
    "shutil.rmtree(sub_folder) # comment out if you want to keep the downloaded folder contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test you can read the pickle file\n",
    "#gdf_Global = pd.read_pickle(download_folder / 'ne_10m_admin_0_countries.pkl')\n",
    "\n",
    "gdf_Global.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. U.S. State and County geographic boundaries <a class=\"anchor\" id=\"s7\"></a>\n",
    "\n",
    "You can get U.S. geospatial data from here for free (you just have to say where you got the data from if you use it):\n",
    "\n",
    "https://hifld-geoplatform.opendata.arcgis.com\n",
    "\n",
    "Home page for all available boundary data:\n",
    "\n",
    "* https://hifld-geoplatform.opendata.arcgis.com/search?groupIds=e5cf7f3805274fef90100ab704ee2ac1\n",
    "\n",
    "Home page for State-level boundaries data (provided by U.S. Census Bureau):\n",
    "\n",
    "* https://hifld-geoplatform.opendata.arcgis.com/datasets/us-state-boundaries\n",
    "* Zip file: https://www2.census.gov/geo/tiger/TIGER2017/STATE/tl_2017_us_state.zip\n",
    "* Attribution (required): U.S. Census Bureau\n",
    "\n",
    "Home page for County-level boundaries data (provided by U.S. Census Bureau):\n",
    "\n",
    "* https://hifld-geoplatform.opendata.arcgis.com/datasets/us-county-boundaries\n",
    "* Zip file: https://www2.census.gov/geo/tiger/TIGER2017/COUNTY/tl_2017_us_county.zip\n",
    "* Attribution (required): U.S. Census Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_url = 'https://www2.census.gov/geo/tiger/TIGER2017/'\n",
    "zip_file_path = 'STATE/tl_2017_us_state.zip'\n",
    "\n",
    "sub_folder = download_folder / 'shapes_state'\n",
    "\n",
    "urlcleanup()\n",
    "with urlopen(geodata_url + zip_file_path) as zip_response:\n",
    "    with ZipFile(BytesIO(zip_response.read())) as zip_file:\n",
    "        zip_file.extractall(sub_folder)\n",
    "        \n",
    "gdf_US_State = gpd.read_file(sub_folder / 'tl_2017_us_state.shp')\n",
    "gdf_US_State.to_pickle(download_folder / 'tl_2017_us_state.pkl')\n",
    "\n",
    "shutil.rmtree(sub_folder) # comment out if you want to keep the downloaded folder contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test you can read the pickle file\n",
    "# gdf_US_State = pd.read_pickle(download_folder / 'tl_2017_us_state.pkl')\n",
    "\n",
    "gdf_US_State.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'COUNTY/tl_2017_us_county.zip'\n",
    "\n",
    "sub_folder = download_folder / 'shapes_county'\n",
    "\n",
    "urlcleanup()\n",
    "with urlopen(geodata_url + zip_file_path) as zip_response:\n",
    "    with ZipFile(BytesIO(zip_response.read())) as zip_file:\n",
    "        zip_file.extractall(sub_folder)\n",
    "\n",
    "gdf_US_County = gpd.read_file(sub_folder / 'tl_2017_us_county.shp')\n",
    "gdf_US_County.to_pickle(download_folder / 'tl_2017_us_county.pkl')\n",
    "\n",
    "shutil.rmtree(sub_folder) # comment out if you want to keep the downloaded folder contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test you can read the pickle file\n",
    "#gdf_US_County = pd.read_pickle(download_folder / 'tl_2017_us_county.pkl')\n",
    "\n",
    "gdf_US_County.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. The data is downloaded and ready for use <a class=\"anchor\" id=\"s8\"></a>\n",
    "\n",
    "You now have all the data needed to begin tracking, analyzing, and visualizing the COVID-19 pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
